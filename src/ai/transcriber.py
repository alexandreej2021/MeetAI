"""
M√≥dulo de transcri√ß√£o usando OpenAI Whisper
"""

import openai
import os
from pathlib import Path
import json
import wave
import numpy as np
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

class Transcriber:
    def __init__(self):
        self.client = None
        self.load_config()
    
    def load_config(self):
        """Carregar configura√ß√µes da API"""
        config_file = Path("config/api_keys.json")
        if config_file.exists():
            with open(config_file, 'r') as f:
                config = json.load(f)
                api_key = config.get('openai_api_key')
                if api_key:
                    self.client = openai.OpenAI(api_key=api_key)
    
    def get_file_size_mb(self, file_path):
        """Obter tamanho do arquivo em MB"""
        return os.path.getsize(file_path) / (1024 * 1024)
    
    def split_audio_file(self, input_file, max_size_mb=20):
        """Dividir arquivo de √°udio em peda√ßos menores se necess√°rio"""
        file_size_mb = self.get_file_size_mb(input_file)
        
        if file_size_mb <= max_size_mb:
            return [input_file]  # Arquivo pequeno o suficiente
        
        print(f"üìÇ Arquivo muito grande ({file_size_mb:.1f}MB). Dividindo em peda√ßos...")
        
        # Abrir arquivo WAV
        with wave.open(input_file, 'rb') as wav_file:
            frames = wav_file.readframes(wav_file.getnframes())
            params = wav_file.getparams()
            
            # Calcular quantos peda√ßos precisamos
            num_chunks = int(np.ceil(file_size_mb / max_size_mb))
            frames_per_chunk = len(frames) // num_chunks
            
            chunk_files = []
            temp_dir = Path("temp")
            temp_dir.mkdir(exist_ok=True)
            
            for i in range(num_chunks):
                chunk_filename = temp_dir / f"chunk_{i+1}.wav"
                
                start_frame = i * frames_per_chunk
                if i == num_chunks - 1:  # √öltimo peda√ßo
                    end_frame = len(frames)
                else:
                    end_frame = (i + 1) * frames_per_chunk
                
                chunk_frames = frames[start_frame:end_frame]
                
                # Salvar peda√ßo
                with wave.open(str(chunk_filename), 'wb') as chunk_file:
                    chunk_file.setparams(params)
                    chunk_file.writeframes(chunk_frames)
                
                chunk_files.append(str(chunk_filename))
                print(f"  üìÑ Peda√ßo {i+1}/{num_chunks}: {chunk_filename.name}")
        
        return chunk_files
    
    def cleanup_temp_files(self, temp_files):
        """Limpar arquivos tempor√°rios"""
        for temp_file in temp_files:
            try:
                if os.path.exists(temp_file) and "chunk_" in temp_file:
                    os.remove(temp_file)
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao remover arquivo tempor√°rio {temp_file}: {e}")
    
    def transcribe(self, audio_file):
        """Transcrever arquivo de √°udio"""
        if not self.client:
            raise Exception("API Key da OpenAI n√£o configurada")
        
        if not os.path.exists(audio_file):
            raise Exception(f"Arquivo de √°udio n√£o encontrado: {audio_file}")
        
        try:
            # Verificar tamanho do arquivo e dividir se necess√°rio
            file_size_mb = self.get_file_size_mb(audio_file)
            print(f"üìÅ Tamanho do arquivo: {file_size_mb:.1f}MB")
            
            if file_size_mb > 15:  # Limite otimizado para melhor paralelismo
                return self._transcribe_large_file(audio_file)
            else:
                return self._transcribe_single_file(audio_file)
                
        except Exception as e:
            print(f"Erro na transcri√ß√£o: {e}")
            return None
    
    def _transcribe_single_file(self, audio_file):
        """Transcrever um √∫nico arquivo"""
        with open(audio_file, "rb") as audio:
            response = self.client.audio.transcriptions.create(
                model="whisper-1",
                file=audio,
                language="pt"  # Portugu√™s
            )
        return response.text
    
    def _transcribe_large_file(self, audio_file):
        """Transcrever arquivo grande dividindo em peda√ßos com processamento paralelo"""
        print("üîÑ Processando arquivo grande com transcri√ß√£o simult√¢nea...")
        
        # Dividir arquivo em peda√ßos menores para melhor paralelismo
        chunk_files = self.split_audio_file(audio_file, max_size_mb=12)
        
        if len(chunk_files) == 1:
            # Arquivo n√£o foi dividido
            return self._transcribe_single_file(audio_file)
        
        # Transcrever peda√ßos em paralelo
        print(f"üöÄ Iniciando transcri√ß√£o simult√¢nea de {len(chunk_files)} peda√ßos...")
        start_time = time.time()
        
        # Usar ThreadPoolExecutor para processamento paralelo
        transcripts = {}
        with ThreadPoolExecutor(max_workers=min(len(chunk_files), 4)) as executor:
            # Submeter todas as tarefas
            future_to_index = {
                executor.submit(self._transcribe_chunk_with_index, i, chunk_file): i 
                for i, chunk_file in enumerate(chunk_files)
            }
            
            # Coletar resultados conforme completam
            for future in as_completed(future_to_index):
                chunk_index = future_to_index[future]
                try:
                    result = future.result()
                    if result:
                        transcripts[chunk_index] = result
                        print(f"‚úÖ Peda√ßo {chunk_index + 1}/{len(chunk_files)} conclu√≠do")
                    else:
                        print(f"‚ùå Erro no peda√ßo {chunk_index + 1}/{len(chunk_files)}")
                except Exception as e:
                    print(f"‚ùå Erro ao processar peda√ßo {chunk_index + 1}: {e}")
        
        # Montar transcri√ß√£o final na ordem correta
        full_transcript = ""
        for i in range(len(chunk_files)):
            if i in transcripts:
                if full_transcript and not full_transcript.endswith(" "):
                    full_transcript += " "
                full_transcript += transcripts[i]
            else:
                print(f"‚ö†Ô∏è Peda√ßo {i + 1} n√£o foi transcrito com sucesso")
        
        elapsed_time = time.time() - start_time
        print(f"‚è±Ô∏è Transcri√ß√£o simult√¢nea conclu√≠da em {elapsed_time:.1f} segundos")
        
        # Limpar arquivos tempor√°rios
        self.cleanup_temp_files(chunk_files)
        
        return full_transcript if full_transcript else None
    
    def _transcribe_chunk_with_index(self, index, chunk_file):
        """Transcrever um peda√ßo espec√≠fico com √≠ndice (para processamento paralelo)"""
        try:
            print(f"üéØ Iniciando peda√ßo {index + 1}...")
            result = self._transcribe_single_file(chunk_file)
            return result
        except Exception as e:
            print(f"‚ùå Erro ao transcrever peda√ßo {index + 1}: {e}")
            return None
    
    def transcribe_with_timestamps(self, audio_file):
        """Transcrever com timestamps (para funcionalidade futura)"""
        if not self.client:
            raise Exception("API Key da OpenAI n√£o configurada")
        
        try:
            with open(audio_file, "rb") as audio:
                response = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio,
                    language="pt",
                    response_format="verbose_json",
                    timestamp_granularities=["segment"]
                )
            
            return response.segments
            
        except Exception as e:
            print(f"Erro na transcri√ß√£o com timestamps: {e}")
            return None